{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Ph8LbwM4DfjU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **실습 시작전 런타임 환경 확인: 상단 탭 Runtime --> change runtime type --> Python3 T4GPU**"
      ],
      "metadata": {
        "id": "KSaCjrtop5e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Session 1: transformers 라이브러리를 이용한 소형언어모델 호출 및 실행**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hYjy2AKdR4kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate accelerate torch huggingface_hub"
      ],
      "metadata": {
        "id": "ZEqfhV0iRcQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import huggingface_hub"
      ],
      "metadata": {
        "id": "UL8wKT2aRdj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama, Gemma 등 접근 권한을 관리하는 모델의 경우 로그인 -> Token 생성 -> 접근 승인 과정이 필요\n",
        "# huggingface_hub.login() #회원가입 > Setting 클릭 > Assess Tokens 클릭 > New Tokens 클릭"
      ],
      "metadata": {
        "id": "FwTKuYoyRdmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\""
      ],
      "metadata": {
        "id": "fJfs3FEARdo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **pipeline 모듈을 이용한 생성**"
      ],
      "metadata": {
        "id": "pl6FzJxtnAqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    tokenizer=tokenizer,\n",
        "    dtype=torch.bfloat16,\n",
        "    # torch_dtype=torch.float32,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 사이버대학교의 진학상담 챗봇이다. 항상 한글로 상담사 처럼 대답해\"},\n",
        "    {\"role\": \"user\", \"content\": \"너는 누구니?\"},\n",
        "]\n",
        "\n",
        "outputs = pipe(messages)\n",
        "\n",
        "print(outputs[0][\"generated_text\"][-1]['content'])"
      ],
      "metadata": {
        "id": "-ndcsAYDRdrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs   # 코드 수준에서는 리스트 내부에 딕셔너리 형태로 생성된 텍스트가 저장"
      ],
      "metadata": {
        "id": "NaDTqsSARdt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **이전 대화 기록을 바탕으로한 생성**"
      ],
      "metadata": {
        "id": "5GNgfSKImrdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = outputs[0][\"generated_text\"]\n",
        "chat.append({\"role\": \"user\", \"content\": \"인공지능 분야 대학원 진학을 하고 싶은데 전망은 어때?\"})\n",
        "outputs = pipe(chat)\n",
        "print(outputs[0][\"generated_text\"][-1]['content'])"
      ],
      "metadata": {
        "id": "vg_kncs-RdwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GPU 메모리 점유율 확인**"
      ],
      "metadata": {
        "id": "s1cnngNKnixu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "seGIXI-c18Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **원활한 실습을 위한 세션 재실행 (상단 탭 Runtime --> Restart session --> !nvidia-smi)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZBFj285Nns0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **소형언어모델의 메소드를 이용한 토크나이저 형태 및 생성 결과 확인**"
      ],
      "metadata": {
        "id": "H5nPCS4X15Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import huggingface_hub\n",
        "\n",
        "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\""
      ],
      "metadata": {
        "id": "8PRJ2c1lnZDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, device_map=\"cpu\") # CPU 환경에서 구동할경우 device_map=\"cpu\"\n",
        "\n",
        "tokenizer.save_pretrained(\"tokenizer_sample\")"
      ],
      "metadata": {
        "id": "QC_f4OuARdyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **토크나이저의 출력값 확인(서브워드 토크나이저 특성)**"
      ],
      "metadata": {
        "id": "fVlL5DlwofpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence = \"너는 사이버대학교의 진학상담 챗봇이다. 항상 한글로 상담사 처럼 대답해\" # 한글 예제\n",
        "sequence = \"model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, device_map=cpu)\" # 영어 및 코드 텍스트 예제\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens) # 바이트 수준으로 구분된 토큰 확인"
      ],
      "metadata": {
        "id": "XV4J5aMdRd0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98ac231-b28c-4a8b-e897-817f3dc8cd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['model', 'Ġ=', 'ĠAuto', 'Model', 'For', 'C', 'ausal', 'LM', '.from', '_pre', 'trained', '(model', '_id', ',', 'Ġtrust', '_remote', '_code', '=True', ',', 'Ġdevice', '_map', '=', 'cpu', ')']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids) # 각 토큰은 인덱스 값을 가짐"
      ],
      "metadata": {
        "id": "b4mlHkawRqym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5a608e-b90f-458e-e6eb-4a284ddc42f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2528, 284, 8979, 1712, 2461, 34, 79074, 10994, 6387, 10442, 35722, 7635, 842, 11, 6950, 36425, 4136, 3618, 11, 3671, 5376, 28, 16475, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 사이버대학교의 진학상담 챗봇이다. 항상 한글로 상담사 처럼 대답해\"},\n",
        "    {\"role\": \"user\", \"content\": \"너는 누구니?\"},\n",
        "]\n",
        "messages_chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
      ],
      "metadata": {
        "id": "li61OYugRqwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages_chat # 토크나이저에 입력되는 약속된 형태의 템플릿"
      ],
      "metadata": {
        "id": "uW7VDbWzs6Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(messages_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
        "inputs = {key: tensor.to(\"cuda\") for key, tensor in inputs.items()}\n",
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "JMidxU02Rqtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs # 실제 소형언어모델로 입력되는 형태 확인"
      ],
      "metadata": {
        "id": "cU4CXHt0RqrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모델의 메소드를 이용한 생성결과 확인**"
      ],
      "metadata": {
        "id": "DOWtS-eYpDAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "            \"max_new_tokens\": 100,\n",
        "            \"num_beams\": 4,\n",
        "            \"no_repeat_ngram_size\": 2,\n",
        "            \"early_stopping\": True,\n",
        "            \"do_sample\": True,\n",
        "            \"temperature\": 0.7,\n",
        "            \"pad_token_id\": tokenizer.eos_token_id\n",
        "        }\n",
        "\n",
        "outputs = model.generate(**inputs,  **generation_config)\n",
        "decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):], skip_special_tokens=True)\n",
        "print(\"Decoded output:\\n\", decoded_output)"
      ],
      "metadata": {
        "id": "EhDXTLTvRqow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0] # 출력 결과: 토큰 인덱스"
      ],
      "metadata": {
        "id": "r7T_hGVERqmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **출력결과 시현을 위한 후처리 과정 이해**"
      ],
      "metadata": {
        "id": "JoT8tZg9uh_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['input_ids'].size(1)"
      ],
      "metadata": {
        "id": "igEpQtvqRd3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0][inputs['input_ids'].size(1):].size(0) # 모델 출력에서 입력값의 토큰 수만큼을 제외한 나머지만 시현"
      ],
      "metadata": {
        "id": "SXwi4z7NRd50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # GPU 메모리 점유율 확인"
      ],
      "metadata": {
        "id": "Sw2iTtrkyi17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **원활한 실습을 위한 세션 재실행 (상단 탭 Runtime --> Restart session --> !nvidia-smi)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5i_A1xAW4PCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Session 2: 올라마(Ollama) 라이브러리를 이용한 RAG 실습**"
      ],
      "metadata": {
        "id": "sfELS3Dwpl6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **사전 준비: Ollama Installation & Execution(구 버전)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ph8LbwM4DfjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm"
      ],
      "metadata": {
        "id": "QC4ZS2GHJugu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "id": "2DsQMHK1KKtn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "UZIgr2Q3_rXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm # ollama serve &"
      ],
      "metadata": {
        "id": "8Q50N3ZLEi-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "v-Q3zt14ALfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama --version"
      ],
      "metadata": {
        "id": "hb3D92MaAaZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!killall ollama"
      ],
      "metadata": {
        "id": "PNs4NhW3BMFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull aya:8b\n",
        "# !ollama pull aya-expanse:8b"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L5_WYd8nAmt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm # ollama run aya-expanse:8b"
      ],
      "metadata": {
        "id": "BZ1Md8Q3JJlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8P3C5IJOuvPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **사전 준비: Ollama Installation & Execution(새 버전)**\n"
      ],
      "metadata": {
        "id": "2juAaqztu2sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update && sudo apt-get install -y zstd\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "!pip install ollama -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dTyCTQRlvGKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Session 2-1: Ollama 기초 활용**"
      ],
      "metadata": {
        "id": "7C1qGsSBxAfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ollama 환경 실행**"
      ],
      "metadata": {
        "id": "TJswb3BDygUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import ollama\n",
        "\n",
        "subprocess.run([\"pkill\", \"ollama\"]) # 터미널 기준 >> pkill -9 ollama\n",
        "subprocess.Popen(['ollama', 'serve']) # 터미널 기준 >> ollama serve\n",
        "while True:\n",
        "    try:\n",
        "        ollama.list()\n",
        "        print(\"\\n✅ 서버 준비 완료! 이제 AI와 대화할 수 있습니다.\")\n",
        "        break\n",
        "    except Exception:\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "id": "HiWiN-ZRvn6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list # 활용 가능한 모델 종류 확인"
      ],
      "metadata": {
        "id": "TYy5AeKUwZmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama --version"
      ],
      "metadata": {
        "id": "TZdGAaDMwaRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "SNY8lXOXyALF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **소형 언어모델 다운로드**"
      ],
      "metadata": {
        "id": "pWvDSV9XxH9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ollama pull aya:8b\n",
        "!ollama pull qwen2.5:1.5b\n",
        "\n",
        "# ollama 에서 제공하는 모델 종류 참조 페이지: https://ollama.com/search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj4wHwY2wfk-",
        "outputId": "44bf2ee0-2bf5-4f98-f61a-5cda4ff4c6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list # 활용 가능한 모델 종류 확인"
      ],
      "metadata": {
        "id": "o8GmfYUKw8S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ONbr0ivlwwgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ollama 메소드를 활용한 텍스트 생성**"
      ],
      "metadata": {
        "id": "gw52NrzNxQ58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "\n",
        "# model_name = 'aya:8b'\n",
        "model_name = 'qwen2.5:1.5b'\n",
        "\n",
        "result_stream = ollama.chat(\n",
        "      model=model_name,\n",
        "      messages=messages,\n",
        "      stream=True,\n",
        "      # stream=False,\n",
        "      # keep_alive=0\n",
        "    )\n",
        "\n",
        "for chunk in result_stream:\n",
        "    content = chunk['message']['content']\n",
        "    print(chunk['message']['content'], end='', flush=True)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "QniLBHbv9_nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stream이 False 인 경우\n",
        "contents_output = result_stream.message.content\n",
        "contents_output"
      ],
      "metadata": {
        "id": "1yrn0Beu4kUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # GPU 메모리 점유율 확인"
      ],
      "metadata": {
        "id": "J3Hg9tcR4z1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Session 2-2: RAG 적용을 위한 전처리(pre-processing)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f3PEv3gnDRdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **RAG 모듈 및 pdf 파일 처리를 위한 라이브러리 설치**"
      ],
      "metadata": {
        "id": "gTZjSvgky3PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community langchain-text-splitters langchain_huggingface sentence_transformers pdfplumber pypdf faiss-cpu -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nRdV6uxDDQdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "HwvyE0D-D5u7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **pdf 파일 로드 및 텍스트 구조 확인**"
      ],
      "metadata": {
        "id": "wa4Kwbyvy-Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record_file = 'rag_example.pdf'\n",
        "\n",
        "loader = PyPDFLoader(record_file)\n",
        "documents = loader.load()\n",
        "filtered_doc = documents[1:4]"
      ],
      "metadata": {
        "id": "89pPvQehD-R6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_doc # pdf 파일 로드 후 텍스트 저장 변수 구조"
      ],
      "metadata": {
        "id": "hJKJXDxdEAse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **검색 효율성 향상을 위한 텍스트 청킹(chunking)**"
      ],
      "metadata": {
        "id": "cs7GCCDOzxHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
        "chunking_data = text_splitter.split_documents(filtered_doc)"
      ],
      "metadata": {
        "id": "cra5LemFECJo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunking_data[0:4]"
      ],
      "metadata": {
        "id": "dupYn_MIEDxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **표 데이터 추출 후 텍스트 청킹**"
      ],
      "metadata": {
        "id": "GHMNM8YU0lhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables = []\n",
        "with pdfplumber.open(record_file) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        table = page.extract_table()\n",
        "        if table:\n",
        "            df = pd.DataFrame(table[1:], columns=table[0])\n",
        "            tables.append(df)"
      ],
      "metadata": {
        "id": "yx5JPbr_EFjf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tables) # 추출 된 테이블의 수"
      ],
      "metadata": {
        "id": "Ijge7JkYEHg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables[0] # 테이블 예시"
      ],
      "metadata": {
        "id": "ACpuF9XbEJZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **추출 된 표 중 특정 범위에 대해서만 Vector DB화**"
      ],
      "metadata": {
        "id": "89oTKI8T0_LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tables = tables[7:21]\n",
        "text_dict = defaultdict()\n",
        "text = \"\""
      ],
      "metadata": {
        "id": "E9wu2L3aENPG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 전처리(정규 표현식 활용)\n",
        "for i, table in enumerate(filtered_tables):\n",
        "    if isinstance(table, pd.DataFrame):\n",
        "        table = table.ffill() # 데이터 채우기(이전 행의 값 그대로 사용)\n",
        "        table = table.apply(lambda x: table.columns + \":\" + x.astype(str), axis=1)\n",
        "        tmp_text = table.to_csv(index=False, header=False)\n",
        "        tmp_text = re.sub(r'\\n\"보 장', 'TEMP_REPLACE', tmp_text)\n",
        "        tmp_text = re.sub(r'\\n보 장', 'TEMP_2REPLACE', tmp_text)\n",
        "        tmp_text = re.sub(r'\\n', ' ', tmp_text)\n",
        "        tmp_text = re.sub(r'TEMP_REPLACE', '\\n\"보 장', tmp_text)\n",
        "        tmp_text = re.sub(r'TEMP_2REPLACE', '\\n\"보 장', tmp_text)\n",
        "        text_dict[i] = tmp_text.split(\"\\n\")\n",
        "        text += tmp_text"
      ],
      "metadata": {
        "id": "EyHK8bJYEOcO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = list(itertools.chain(*text_dict.values()))"
      ],
      "metadata": {
        "id": "QGvzsLSIEQbY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list[0] # 결과 확인"
      ],
      "metadata": {
        "id": "d98rSPdG1gXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Vector DB에 입력하기 위한 형식으로 변환**"
      ],
      "metadata": {
        "id": "QaJfmnjM1vrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunking_data = [Document(page_content=page, metadata=dict(page=i)) for i, page in enumerate(text_list)]"
      ],
      "metadata": {
        "id": "b8c8VbBHEQ85"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunking_data # 결과 확인"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GB_dVRA0ETFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Session 2-3: RAG 적용**\n",
        "\n",
        "*   벡터 스토어 라이브러리: 벡터 유사도 검색(FAISS)\n",
        "*   임베딩 모델: 문장을 임베딩 벡터로 투영\n",
        "\n"
      ],
      "metadata": {
        "id": "pUSwepJMFjF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import ollama\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import re\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "A5S0FWdBFn2n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **임베딩 모델 호출(SentenceTransformer 라이브러리 활용)**"
      ],
      "metadata": {
        "id": "B_nZhF6U2SGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BAAI/bge-m3\"\n",
        "if not os.path.exists(model_name):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    model.save(model_name)"
      ],
      "metadata": {
        "id": "27F4tuDjFpfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={\n",
        "        'device': \"cuda\",\n",
        "        'trust_remote_code': True,\n",
        "    },\n",
        "    encode_kwargs={'normalize_embeddings': True},\n",
        ")"
      ],
      "metadata": {
        "id": "NpCBFJyoFpiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **문장의 임베딩 변환결과 예시**"
      ],
      "metadata": {
        "id": "r1wXihkB2yMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_vectors = embeddings.embed_documents([\n",
        "    \"안녕하세요.\",\n",
        "    \"반갑습니다.\",\n",
        "    \"감사합니다.\",\n",
        "])\n",
        "print(emb_vectors[0][:4])\n",
        "print(emb_vectors[1][:4])\n",
        "print(emb_vectors[2][:4])"
      ],
      "metadata": {
        "id": "IAb13JulFpki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(emb_vectors[0])"
      ],
      "metadata": {
        "id": "x2G7SFJNFpm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **외부 참조 데이터 전처리(이전 세션 과정과 동일)**"
      ],
      "metadata": {
        "id": "PeU4P3_03Idm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunking_data = \"\""
      ],
      "metadata": {
        "id": "NpxlW2cPFppl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_file = 'rag_example.pdf'\n",
        "\n",
        "tables = []\n",
        "with pdfplumber.open(record_file) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        table = page.extract_table()\n",
        "        if table:\n",
        "            df = pd.DataFrame(table[1:], columns=table[0])\n",
        "            tables.append(df)\n",
        "\n",
        "filtered_tables = tables[7:21]\n",
        "text_dict = defaultdict()\n",
        "text = \"\"\n",
        "\n",
        "for i, table in enumerate(filtered_tables):\n",
        "    if isinstance(table, pd.DataFrame):\n",
        "        table = table.ffill() # 데이터 채우기(이전 행의 값 그대로 사용)\n",
        "        table = table.apply(lambda x: table.columns + \":\" + x.astype(str), axis=1)\n",
        "        tmp_text = table.to_csv(index=False, header=False)\n",
        "        tmp_text = re.sub(r'\\n\"보 장', 'TEMP_REPLACE', tmp_text)\n",
        "        tmp_text = re.sub(r'\\n보 장', 'TEMP_2REPLACE', tmp_text)\n",
        "        tmp_text = re.sub(r'\\n', ' ', tmp_text)\n",
        "        tmp_text = re.sub(r'TEMP_REPLACE', '\\n\"보 장', tmp_text)\n",
        "        tmp_text = re.sub(r'TEMP_2REPLACE', '\\n\"보 장', tmp_text)\n",
        "        text_dict[i] = tmp_text.split(\"\\n\")\n",
        "        text += tmp_text\n",
        "\n",
        "text_list = list(itertools.chain(*text_dict.values()))\n",
        "chunking_data = [Document(page_content=page, metadata=dict(page=i)) for i, page in enumerate(text_list)]"
      ],
      "metadata": {
        "id": "nFpxJXYaFpsC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **청킹 된 외부 참조 데이터를 벡터 DB에 저장**"
      ],
      "metadata": {
        "id": "2lwB_2aS26ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.from_documents(chunking_data, embeddings)"
      ],
      "metadata": {
        "id": "Ri-MWJJiFpuh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **보험 청구인의 사고 사례(예시)**"
      ],
      "metadata": {
        "id": "0PGNzLCZ3VKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_str = \"\""
      ],
      "metadata": {
        "id": "NOgwFMlcFpxH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_info = defaultdict(list)\n",
        "medical_info[\"hospital_1\"] = (\n",
        "    '질병 또는 부상명: (S52590) 요골 하단의 상세불명 골절, 폐쇄성, '\n",
        "    '(S62630) 기타 손가락의 중지골 골절, 폐쇄성, '\n",
        "    '(S836) 무릎의 기타 및 상세불명 부분의 염좌 및 긴장, '\n",
        "    '(M2416) 기타 관절연골장애, 무릎관절, '\n",
        "    '(M2406) 관절안의 유리체 무릎관절, '\n",
        "    '(M6586) 기타 윤활막염 및 힘줄윤활막염 무릎관절. '\n",
        "    '\\n치료기간: 입원 2022년 11월 26일부터 2022년 12월 24일까지(29 일간). '\n",
        "    '\\n소견서 내용: 상기환자는 2022/11/1 넘어져 수상후 타병원 진료후 내원하신 환자로 '\n",
        "    '우측 요골부, 우측 제4 수지부의 골절 진단과 우측 무릎의 통증으로 '\n",
        "    '안정가료 및 통증완화에 대한 치료를 위하여 상기 기간 동안 입원치료하였으며 '\n",
        "    '추후 우측 손목, 무릎의 지속적인 관찰 및 재활치료가 필요 할 것으로 사료됨. '\n",
        "    '\\n의료기관 명칭: 사각 종합병원\\n\\n'\n",
        ")\n",
        "\n",
        "medical_info[\"hospital_2\"] = (\n",
        "    '질병 또는 부상명: (M2416) 기타 관절연골장애 아래다리, '\n",
        "    '(M2406) 관절안의 유리체, 아래다리, '\n",
        "    '(M6586) 기타 윤활막염 및 힘줄윤활막염 아래다리, '\n",
        "    '(M170) 앙쪽 원발성 무릎관절증, '\n",
        "    '(S52590) 요골 하단의 상세불명 골절, 폐쇄성, '\n",
        "    '(S62630) 기타 손가락의 중지골 골절, 폐쇄성. '\n",
        "    '\\n치료기간: 입원 2022년 12월 24일부터 2023년 01월 10일까지(18 일간). '\n",
        "    '\\n소견서 내용: 상기환자 양측 무릎과 우측 손목, 우측 네번째 손가락 통증으로 입원한 환자로 '\n",
        "    '이학적 검사 및 단순 방사선 검사상 상기 병명으로 진단되었으며 '\n",
        "    'VAS 7의 무릎 통중과 우측 손목 손가락 골절로 인한 ROM 제한으로 증상 호전시끼지 '\n",
        "    '물리치료, 도수치료, 체외 충격파 치료 등 보존적 치료가 필요할 것으로 판단됨 '\n",
        "    '상기 소견은 초진 소견이며, 추후 경과에 따라 재평가 요함.'\n",
        "    '\\n구두소견: 사각 병원에서 치료 후에 전원 온 환자로 입원 경위에 대해서는, '\n",
        "    '골절, 관절 내 유리체, 퇴행성 관절염, 강직 등 단순 통증으로 내원한 것 외에는, '\n",
        "    '더 이상 드릴 답변 없음. '\n",
        "    '필요시 더 입원을 할 수도 있는 환자이고 심평원 적정 의료 기준에 따라 퇴원시킨 것으로, '\n",
        "    '적정입원기간을 명확하게 산정하기 어려움.'\n",
        "    '\\n의료기관 명칭: 서울 창업허브 종합병원\\n\\n'\n",
        ")\n",
        "\n",
        "medical_info[\"interview_1\"] = (\n",
        "    '고객 안내일자: 2023-02-08.'\n",
        "    '\\n고객 안내내용: 현장심사 안내.'\n",
        "    '\\n고객 반응: 문답서 작성과 면담을 거부함.'\n",
        ")\n",
        "\n",
        "medical_info[\"interview_2\"] = (\n",
        "    '고객 안내일자: 2023-03-17.'\n",
        "    '\\n고객 안내내용: 최초 내원경위로 2022.11.1에 넘어지고 나서, '\n",
        "    '요골 하단의 상세불명 골절, 폐쇄성 진단으로 주병명이 확인되어, '\n",
        "    '재해로 검토되어질 수 있음을 안내.'\n",
        "    '\\n고객 반응: 넘어져서 내원한 것은 맞으나, '\n",
        "    '어깨, 무릎 등은 원래부터 가지고 있는 질병으로 인해 입원치료를 받은 것이니, '\n",
        "    '질병으로 처리됨이 타당함.'\n",
        ")\n",
        "\n",
        "values_list = list(medical_info.values())\n",
        "result_string = ' '.join(values_list)"
      ],
      "metadata": {
        "id": "t2TQ1Ku8Fpzq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **RAG가 적용되지 않은 상태에서의 생성 결과**"
      ],
      "metadata": {
        "id": "sWaDMp4g3dFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 전문성이 매우 높은 수준의 손해사정보고서 작성 챗봇이야. 전문적인 용어로 답변해\"},\n",
        "    {\"role\": \"user\", \"content\": \"아래의 조사기록을 분석해서 손해사정보고서 작성\" + result_string},\n",
        "]\n",
        "\n",
        "result_stream = ollama.chat(\n",
        "      # model=\"aya:8b\",\n",
        "      model=\"qwen2.5:1.5b\",\n",
        "      messages=messages,\n",
        "      stream=True\n",
        "    )"
      ],
      "metadata": {
        "id": "rDYqmBivFp2A"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents_output = result_stream.message.content"
      ],
      "metadata": {
        "id": "DcUcet6hPDcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in result_stream:\n",
        "    content = chunk['message']['content']\n",
        "    print(chunk['message']['content'], end='', flush=True)"
      ],
      "metadata": {
        "id": "aTUymfVwFp7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **RAG 적용을 위해 벡터 DB에 저장된 텍스트와 유사도 비교**"
      ],
      "metadata": {
        "id": "9Vq1UnbW4p0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_docs = vector_store.similarity_search(result_string, k=3)"
      ],
      "metadata": {
        "id": "GdM5iCNzFp9o"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_context = \"\\n\".join(doc.page_content for doc in relevant_docs)"
      ],
      "metadata": {
        "id": "couK7wNjFqAU"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_context # 유사도 비교 후 선택된 가장 유사한 정보 3개"
      ],
      "metadata": {
        "id": "ieVyd_ZsFqC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt = (\n",
        "        f'Context: {insurance_context} \\n '\n",
        "        f'Question: 위의 데이터를 바탕으로 다음의 손해사정보고서에 기록된 질병 또는 부상에 대한 보험금 지급 여부 및 예상금액 판단 \\n'\n",
        "        f' {contents_output}'\n",
        "    )"
      ],
      "metadata": {
        "id": "8q55Gqw5FqFX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 전문성이 매우 높은 수준의 손해사정보고서 작성 챗봇이야. 전문적인 용어로 답변해\"},\n",
        "    {\"role\": \"user\", \"content\": \"아래의 조사기록을 분석해서 손해사정보고서 작성\" + result_string},\n",
        "    {\"role\": \"assistant\", \"content\": contents_output},\n",
        "    {\"role\": \"user\", \"content\": input_prompt},\n",
        "]"
      ],
      "metadata": {
        "id": "jmUloFS2FqH9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_stream = ollama.chat(\n",
        "      # model=\"aya:8b\",\n",
        "      model=\"qwen2.5:1.5b\",\n",
        "      messages=messages,\n",
        "      stream=True\n",
        "    )\n",
        "\n",
        "for chunk in result_stream:\n",
        "    content = chunk['message']['content']\n",
        "    print(chunk['message']['content'], end='', flush=True)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "gr8rc9AfGGbV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}